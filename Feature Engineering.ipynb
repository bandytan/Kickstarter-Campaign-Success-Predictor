{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfcff7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivankoh/opt/miniconda3/envs/bt4222/lib/python3.9/site-packages/gensim/matutils.py:22: DeprecationWarning: Please use `triu` from the `scipy.linalg` namespace, the `scipy.linalg.special_matrices` namespace is deprecated.\n",
      "  from scipy.linalg.special_matrices import triu\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import ast\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "from nltk import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize, TreebankWordTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.util import ngrams\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import spacy\n",
    "import pyLDAvis.gensim_models\n",
    "import en_core_web_md\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models import LdaMulticore\n",
    "from gensim.models import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b667a080",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/Kickstarter_merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30a6a68a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1404\n",
       "0     728\n",
       "Name: has_video, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert 'video' to a binary categorical variable\n",
    "df['video'].value_counts()\n",
    "df['has_video'] = df['video'].apply(lambda x: 0 if pd.isnull(x) else 1)\n",
    "df['has_video'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae6f8c5",
   "metadata": {},
   "source": [
    "NLP features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1445895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text cleaning for: rewards, description, description story, description risks\n",
    "\n",
    "def clean_text(df):\n",
    "    def process_rewards(corpus):\n",
    "    \n",
    "        corpus_processed = []\n",
    "        for row in corpus:\n",
    "            row_processed = \"\"\n",
    "            row = row.replace(\"\\\\n\", \" \")\n",
    "            row = ast.literal_eval(row)\n",
    "\n",
    "            for dict in row:\n",
    "                row_processed += dict['rewards'].lower() + ' '\n",
    "            \n",
    "            \n",
    "            row_processed = row_processed.replace(\"//\",'')\n",
    "            row_processed = re.sub(r'[^\\w\\s]', '', row_processed) # remove punctuation\n",
    "            corpus_processed.append(row_processed)\n",
    "\n",
    "        return corpus_processed\n",
    "    \n",
    "    def process_description_story(corpus):\n",
    "        corpus_processed = []\n",
    "        for row in corpus:\n",
    "            row = str(row)\n",
    "            row_processed = row.replace(\"\\r\", \" \" )\n",
    "            row_processed = row_processed.replace(\"\\n\", \" \" )\n",
    "            row_processed = re.sub(r'[^\\w\\s]', '', row_processed) # remove punctuation\n",
    "            corpus_processed.append(row_processed)\n",
    "\n",
    "        return corpus_processed\n",
    "\n",
    "    df[\"rewards_processed\"] = process_rewards(df[\"rewards\"])\n",
    "    df[\"description_processed\"] = process_description_story(df[\"description\"])\n",
    "    df[\"description_story_processed\"] = process_description_story(df[\"description_story\"])\n",
    "    df[\"description_risks_processed\"] = process_description_story(df[\"description_risks\"])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f95c3473",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LemmatizeTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "    def __call__(self, text):\n",
    "        return [self.lemmatizer.lemmatize(word) for word in word_tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62c9ad03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_nlp_features(df):\n",
    "    \n",
    "    # Rewards\n",
    "\n",
    "    vect_rewards = TfidfVectorizer( \n",
    "        tokenizer=LemmatizeTokenizer(),\n",
    "        lowercase=True,\n",
    "        analyzer='word', \n",
    "        ngram_range=(1,3), # unigram, bigram and trigram \n",
    "        max_features=100, # vocabulary that only consider the top max_features ordered by term frequency across the corpus\n",
    "        min_df=10, # minimum word frequency required to be in model\n",
    "        stop_words=stopwords.words('english') # remove stopwords\n",
    "        )\n",
    "\n",
    "    rewards_processed = pd.Series(df[\"rewards_processed\"])\n",
    "    tfidf_fit_rewards = vect_rewards.fit(rewards_processed)\n",
    "    rewards_tfidf_array = tfidf_fit_rewards.transform(rewards_processed).toarray()\n",
    "    rewards_tfidf_df = pd.DataFrame(rewards_tfidf_array)\n",
    "    rewards_tfidf_df.columns = list(map(lambda x : \"rewards_\" + str(x), rewards_tfidf_df.columns))\n",
    "    df = pd.merge(df, rewards_tfidf_df , left_index=True, right_index=True)\n",
    "    \n",
    "\n",
    "    # Description\n",
    "\n",
    "    vect_description = TfidfVectorizer( \n",
    "        tokenizer=LemmatizeTokenizer(),\n",
    "        lowercase=True,\n",
    "        analyzer='word', \n",
    "        ngram_range=(1,3), # unigram, bigram and trigram \n",
    "        max_features=100, # vocabulary that only consider the top max_features ordered by term frequency across the corpus\n",
    "        min_df=10, # minimum word frequency required to be in model\n",
    "        stop_words=stopwords.words('english') # remove stopwords\n",
    "        )\n",
    "\n",
    "    description = pd.Series(df[\"description_processed\"])\n",
    "    tfidf_fit_description = vect_description.fit(description)\n",
    "    description_tfidf_array = tfidf_fit_description.transform(description).toarray()\n",
    "    description_tfidf_df = pd.DataFrame(description_tfidf_array)\n",
    "    description_tfidf_df.columns = list(map(lambda x : \"description_\" + str(x), description_tfidf_df.columns))\n",
    "    df = pd.merge(df, description_tfidf_df , left_index=True, right_index=True)\n",
    "\n",
    "\n",
    "    # Description Story\n",
    "\n",
    "    vect_description_story = TfidfVectorizer( \n",
    "        tokenizer=LemmatizeTokenizer(),\n",
    "        lowercase=True,\n",
    "        analyzer='word', \n",
    "        ngram_range=(1,3), # unigram, bigram and trigram \n",
    "        max_features=100, # vocabulary that only consider the top max_features ordered by term frequency across the corpus\n",
    "        min_df=10, # minimum word frequency required to be in model\n",
    "        stop_words=stopwords.words('english') # remove stopwords\n",
    "        )\n",
    "    \n",
    "    description_story_processed = pd.Series(df[\"description_story_processed\"])\n",
    "    tfidf_fit_description_story_processed = vect_description_story.fit(description_story_processed)\n",
    "    description_story_processed_tfidf_array = tfidf_fit_description_story_processed.transform(description_story_processed).toarray()\n",
    "    description_story_tfidf_df = pd.DataFrame(description_story_processed_tfidf_array)\n",
    "    description_story_tfidf_df.columns = list(map(lambda x : \"description_story_\" + str(x), description_story_tfidf_df.columns))\n",
    "    df = pd.merge(df, description_story_tfidf_df , left_index=True, right_index=True)\n",
    "\n",
    "\n",
    "    # Description Risks\n",
    "\n",
    "    vect_description_risks = TfidfVectorizer( \n",
    "        tokenizer=LemmatizeTokenizer(),\n",
    "        lowercase=True,\n",
    "        analyzer='word', \n",
    "        ngram_range=(1,3), # unigram, bigram and trigram \n",
    "        max_features=100, # vocabulary that only consider the top max_features ordered by term frequency across the corpus\n",
    "        min_df=10, # minimum word frequency required to be in model\n",
    "        stop_words=stopwords.words('english') # remove stopwords\n",
    "        )\n",
    "\n",
    "    description_risks_processed = pd.Series(df[\"description_risks_processed\"])\n",
    "    tfidf_fit_description_risks_processed = vect_description_risks.fit(description_risks_processed)\n",
    "    description_risks_processed_tfidf_array = tfidf_fit_description_risks_processed.transform(description_risks_processed).toarray()\n",
    "    description_risks_tfidf_df = pd.DataFrame(description_risks_processed_tfidf_array)\n",
    "    description_risks_tfidf_df.columns = list(map(lambda x : \"description_risks_\" + str(x), description_risks_tfidf_df.columns))\n",
    "    df = pd.merge(df, description_risks_tfidf_df , left_index=True, right_index=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "965ebbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bandy\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\feature_extraction\\text.py:524: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "C:\\Users\\bandy\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\feature_extraction\\text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'doe', 'ha', 'might', 'must', \"n't\", 'need', 'sha', 'wa', 'wo', 'would'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\bandy\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\feature_extraction\\text.py:524: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "C:\\Users\\bandy\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\feature_extraction\\text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'doe', 'ha', 'might', 'must', \"n't\", 'need', 'sha', 'wa', 'wo', 'would'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\bandy\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\feature_extraction\\text.py:524: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "C:\\Users\\bandy\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\feature_extraction\\text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'doe', 'ha', 'might', 'must', \"n't\", 'need', 'sha', 'wa', 'wo', 'would'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\Users\\bandy\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\feature_extraction\\text.py:524: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "C:\\Users\\bandy\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\feature_extraction\\text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'doe', 'ha', 'might', 'must', \"n't\", 'need', 'sha', 'wa', 'wo', 'would'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "df = generate_nlp_features(clean_text(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dae2d5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "name\n",
      "description\n",
      "description_story\n",
      "description_risks\n",
      "rewards\n",
      "category\n",
      "pledged\n",
      "goal\n",
      "deadline\n",
      "location\n",
      "state\n",
      "faq_count\n",
      "update_count\n",
      "backers_count\n",
      "is_starrable\n",
      "spotlight\n",
      "staff_pick\n",
      "video\n",
      "creator_name\n",
      "creator_url\n",
      "url\n",
      "created_at\n",
      "published_at\n",
      "launched_at\n",
      "link\n",
      "has_video\n",
      "rewards_processed\n",
      "description_processed\n",
      "description_story_processed\n",
      "description_risks_processed\n",
      "rewards_0\n",
      "rewards_1\n",
      "rewards_2\n",
      "rewards_3\n",
      "rewards_4\n",
      "rewards_5\n",
      "rewards_6\n",
      "rewards_7\n",
      "rewards_8\n",
      "rewards_9\n",
      "rewards_10\n",
      "rewards_11\n",
      "rewards_12\n",
      "rewards_13\n",
      "rewards_14\n",
      "rewards_15\n",
      "rewards_16\n",
      "rewards_17\n",
      "rewards_18\n",
      "rewards_19\n",
      "rewards_20\n",
      "rewards_21\n",
      "rewards_22\n",
      "rewards_23\n",
      "rewards_24\n",
      "rewards_25\n",
      "rewards_26\n",
      "rewards_27\n",
      "rewards_28\n",
      "rewards_29\n",
      "rewards_30\n",
      "rewards_31\n",
      "rewards_32\n",
      "rewards_33\n",
      "rewards_34\n",
      "rewards_35\n",
      "rewards_36\n",
      "rewards_37\n",
      "rewards_38\n",
      "rewards_39\n",
      "rewards_40\n",
      "rewards_41\n",
      "rewards_42\n",
      "rewards_43\n",
      "rewards_44\n",
      "rewards_45\n",
      "rewards_46\n",
      "rewards_47\n",
      "rewards_48\n",
      "rewards_49\n",
      "rewards_50\n",
      "rewards_51\n",
      "rewards_52\n",
      "rewards_53\n",
      "rewards_54\n",
      "rewards_55\n",
      "rewards_56\n",
      "rewards_57\n",
      "rewards_58\n",
      "rewards_59\n",
      "rewards_60\n",
      "rewards_61\n",
      "rewards_62\n",
      "rewards_63\n",
      "rewards_64\n",
      "rewards_65\n",
      "rewards_66\n",
      "rewards_67\n",
      "rewards_68\n",
      "rewards_69\n",
      "rewards_70\n",
      "rewards_71\n",
      "rewards_72\n",
      "rewards_73\n",
      "rewards_74\n",
      "rewards_75\n",
      "rewards_76\n",
      "rewards_77\n",
      "rewards_78\n",
      "rewards_79\n",
      "rewards_80\n",
      "rewards_81\n",
      "rewards_82\n",
      "rewards_83\n",
      "rewards_84\n",
      "rewards_85\n",
      "rewards_86\n",
      "rewards_87\n",
      "rewards_88\n",
      "rewards_89\n",
      "rewards_90\n",
      "rewards_91\n",
      "rewards_92\n",
      "rewards_93\n",
      "rewards_94\n",
      "rewards_95\n",
      "rewards_96\n",
      "rewards_97\n",
      "rewards_98\n",
      "rewards_99\n",
      "description_0\n",
      "description_1\n",
      "description_2\n",
      "description_3\n",
      "description_4\n",
      "description_5\n",
      "description_6\n",
      "description_7\n",
      "description_8\n",
      "description_9\n",
      "description_10\n",
      "description_11\n",
      "description_12\n",
      "description_13\n",
      "description_14\n",
      "description_15\n",
      "description_16\n",
      "description_17\n",
      "description_18\n",
      "description_19\n",
      "description_20\n",
      "description_21\n",
      "description_22\n",
      "description_23\n",
      "description_24\n",
      "description_25\n",
      "description_26\n",
      "description_27\n",
      "description_28\n",
      "description_29\n",
      "description_30\n",
      "description_31\n",
      "description_32\n",
      "description_33\n",
      "description_34\n",
      "description_35\n",
      "description_36\n",
      "description_37\n",
      "description_38\n",
      "description_39\n",
      "description_40\n",
      "description_41\n",
      "description_42\n",
      "description_43\n",
      "description_44\n",
      "description_45\n",
      "description_46\n",
      "description_47\n",
      "description_48\n",
      "description_49\n",
      "description_50\n",
      "description_51\n",
      "description_52\n",
      "description_53\n",
      "description_54\n",
      "description_55\n",
      "description_56\n",
      "description_57\n",
      "description_58\n",
      "description_59\n",
      "description_60\n",
      "description_61\n",
      "description_62\n",
      "description_63\n",
      "description_64\n",
      "description_65\n",
      "description_66\n",
      "description_67\n",
      "description_68\n",
      "description_69\n",
      "description_70\n",
      "description_71\n",
      "description_72\n",
      "description_73\n",
      "description_74\n",
      "description_75\n",
      "description_76\n",
      "description_77\n",
      "description_78\n",
      "description_79\n",
      "description_80\n",
      "description_81\n",
      "description_82\n",
      "description_83\n",
      "description_84\n",
      "description_85\n",
      "description_86\n",
      "description_87\n",
      "description_88\n",
      "description_89\n",
      "description_90\n",
      "description_91\n",
      "description_92\n",
      "description_93\n",
      "description_94\n",
      "description_95\n",
      "description_96\n",
      "description_97\n",
      "description_98\n",
      "description_99\n",
      "description_story_0\n",
      "description_story_1\n",
      "description_story_2\n",
      "description_story_3\n",
      "description_story_4\n",
      "description_story_5\n",
      "description_story_6\n",
      "description_story_7\n",
      "description_story_8\n",
      "description_story_9\n",
      "description_story_10\n",
      "description_story_11\n",
      "description_story_12\n",
      "description_story_13\n",
      "description_story_14\n",
      "description_story_15\n",
      "description_story_16\n",
      "description_story_17\n",
      "description_story_18\n",
      "description_story_19\n",
      "description_story_20\n",
      "description_story_21\n",
      "description_story_22\n",
      "description_story_23\n",
      "description_story_24\n",
      "description_story_25\n",
      "description_story_26\n",
      "description_story_27\n",
      "description_story_28\n",
      "description_story_29\n",
      "description_story_30\n",
      "description_story_31\n",
      "description_story_32\n",
      "description_story_33\n",
      "description_story_34\n",
      "description_story_35\n",
      "description_story_36\n",
      "description_story_37\n",
      "description_story_38\n",
      "description_story_39\n",
      "description_story_40\n",
      "description_story_41\n",
      "description_story_42\n",
      "description_story_43\n",
      "description_story_44\n",
      "description_story_45\n",
      "description_story_46\n",
      "description_story_47\n",
      "description_story_48\n",
      "description_story_49\n",
      "description_story_50\n",
      "description_story_51\n",
      "description_story_52\n",
      "description_story_53\n",
      "description_story_54\n",
      "description_story_55\n",
      "description_story_56\n",
      "description_story_57\n",
      "description_story_58\n",
      "description_story_59\n",
      "description_story_60\n",
      "description_story_61\n",
      "description_story_62\n",
      "description_story_63\n",
      "description_story_64\n",
      "description_story_65\n",
      "description_story_66\n",
      "description_story_67\n",
      "description_story_68\n",
      "description_story_69\n",
      "description_story_70\n",
      "description_story_71\n",
      "description_story_72\n",
      "description_story_73\n",
      "description_story_74\n",
      "description_story_75\n",
      "description_story_76\n",
      "description_story_77\n",
      "description_story_78\n",
      "description_story_79\n",
      "description_story_80\n",
      "description_story_81\n",
      "description_story_82\n",
      "description_story_83\n",
      "description_story_84\n",
      "description_story_85\n",
      "description_story_86\n",
      "description_story_87\n",
      "description_story_88\n",
      "description_story_89\n",
      "description_story_90\n",
      "description_story_91\n",
      "description_story_92\n",
      "description_story_93\n",
      "description_story_94\n",
      "description_story_95\n",
      "description_story_96\n",
      "description_story_97\n",
      "description_story_98\n",
      "description_story_99\n",
      "description_risks_0\n",
      "description_risks_1\n",
      "description_risks_2\n",
      "description_risks_3\n",
      "description_risks_4\n",
      "description_risks_5\n",
      "description_risks_6\n",
      "description_risks_7\n",
      "description_risks_8\n",
      "description_risks_9\n",
      "description_risks_10\n",
      "description_risks_11\n",
      "description_risks_12\n",
      "description_risks_13\n",
      "description_risks_14\n",
      "description_risks_15\n",
      "description_risks_16\n",
      "description_risks_17\n",
      "description_risks_18\n",
      "description_risks_19\n",
      "description_risks_20\n",
      "description_risks_21\n",
      "description_risks_22\n",
      "description_risks_23\n",
      "description_risks_24\n",
      "description_risks_25\n",
      "description_risks_26\n",
      "description_risks_27\n",
      "description_risks_28\n",
      "description_risks_29\n",
      "description_risks_30\n",
      "description_risks_31\n",
      "description_risks_32\n",
      "description_risks_33\n",
      "description_risks_34\n",
      "description_risks_35\n",
      "description_risks_36\n",
      "description_risks_37\n",
      "description_risks_38\n",
      "description_risks_39\n",
      "description_risks_40\n",
      "description_risks_41\n",
      "description_risks_42\n",
      "description_risks_43\n",
      "description_risks_44\n",
      "description_risks_45\n",
      "description_risks_46\n",
      "description_risks_47\n",
      "description_risks_48\n",
      "description_risks_49\n",
      "description_risks_50\n",
      "description_risks_51\n",
      "description_risks_52\n",
      "description_risks_53\n",
      "description_risks_54\n",
      "description_risks_55\n",
      "description_risks_56\n",
      "description_risks_57\n",
      "description_risks_58\n",
      "description_risks_59\n",
      "description_risks_60\n",
      "description_risks_61\n",
      "description_risks_62\n",
      "description_risks_63\n",
      "description_risks_64\n",
      "description_risks_65\n",
      "description_risks_66\n",
      "description_risks_67\n",
      "description_risks_68\n",
      "description_risks_69\n",
      "description_risks_70\n",
      "description_risks_71\n",
      "description_risks_72\n",
      "description_risks_73\n",
      "description_risks_74\n",
      "description_risks_75\n",
      "description_risks_76\n",
      "description_risks_77\n",
      "description_risks_78\n",
      "description_risks_79\n",
      "description_risks_80\n",
      "description_risks_81\n",
      "description_risks_82\n",
      "description_risks_83\n",
      "description_risks_84\n",
      "description_risks_85\n",
      "description_risks_86\n",
      "description_risks_87\n",
      "description_risks_88\n",
      "description_risks_89\n",
      "description_risks_90\n",
      "description_risks_91\n",
      "description_risks_92\n",
      "description_risks_93\n",
      "description_risks_94\n",
      "description_risks_95\n",
      "description_risks_96\n",
      "description_risks_97\n",
      "description_risks_98\n",
      "description_risks_99\n"
     ]
    }
   ],
   "source": [
    "for x in df.columns:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5883c447",
   "metadata": {},
   "source": [
    "**Rewards Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5880f30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rewards_tiers(df):\n",
    "    df[\"reward_tiers\"] = df[\"rewards\"].apply(lambda x : len(ast.literal_eval(x)))\n",
    "    df = move_reward_tiers(df)\n",
    "    return df\n",
    "\n",
    "def create_all_reward_amount(df):\n",
    "    df[\"all_reward_amount\"] = np.empty((len(df), 0)).tolist()\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        all_reward_amount = []\n",
    "        dict_list = ast.literal_eval(df.iloc[i, 5]) # Converts rewards column into dictionary\n",
    "\n",
    "        for dict in dict_list:\n",
    "            values_string = str(dict.values())\n",
    "            reward_title = re.search(r\"Pledge S\\$ \\d{1,3}(,\\d{1,3})? or more\", values_string) # Search for all reward titles\n",
    "\n",
    "            if reward_title is not None:\n",
    "                reward_amount = re.search(r\"\\d{1,3}(,\\d{1,3})?\", reward_title.group()) # Search for only the digits in reward amount\n",
    "                if reward_amount is not None:\n",
    "                    all_reward_amount.append(reward_amount.group())\n",
    "            else:\n",
    "                all_reward_amount.append(0) # If no reward title is found, add 0\n",
    "        df[\"all_reward_amount\"][i] = all_reward_amount\n",
    "    df = move_all_reward_amount(df)\n",
    "    return df\n",
    "\n",
    "# Rearange reward_tiers column to the right of rewards\n",
    "def move_reward_tiers(df):\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[:6] + [cols[-1]] + cols[6:-1]\n",
    "    df = df[cols]\n",
    "    return df\n",
    "\n",
    "# Rearange all_reward_amount column to the right of reward_tiers\n",
    "def move_all_reward_amount(df):\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[:7] + [cols[-1]] + cols[7:-1]\n",
    "    df = df[cols]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a640e9ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>description_story</th>\n",
       "      <th>description_risks</th>\n",
       "      <th>rewards</th>\n",
       "      <th>reward_tiers</th>\n",
       "      <th>category</th>\n",
       "      <th>pledged</th>\n",
       "      <th>goal</th>\n",
       "      <th>...</th>\n",
       "      <th>description_risks_90</th>\n",
       "      <th>description_risks_91</th>\n",
       "      <th>description_risks_92</th>\n",
       "      <th>description_risks_93</th>\n",
       "      <th>description_risks_94</th>\n",
       "      <th>description_risks_95</th>\n",
       "      <th>description_risks_96</th>\n",
       "      <th>description_risks_97</th>\n",
       "      <th>description_risks_98</th>\n",
       "      <th>description_risks_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1249154571</td>\n",
       "      <td>Bunny Care Clinic Pin and Apparel Collection</td>\n",
       "      <td>A small collection of Bunny themed enamel pins...</td>\n",
       "      <td>Story\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\...</td>\n",
       "      <td>We try our best to keep everything on schedule...</td>\n",
       "      <td>[{'rewards': 'Pledge without a reward'}, {'rew...</td>\n",
       "      <td>12</td>\n",
       "      <td>art/illustration</td>\n",
       "      <td>14115.0</td>\n",
       "      <td>700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.296369</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1276054891</td>\n",
       "      <td>Hustle: A Singaporean Card Game</td>\n",
       "      <td>Hustle: A Singaporean Card Game is a funny and...</td>\n",
       "      <td>Story\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\...</td>\n",
       "      <td>We want to be frank and honest with all our ge...</td>\n",
       "      <td>[{'rewards': 'Pledge without a reward'}, {'rew...</td>\n",
       "      <td>2</td>\n",
       "      <td>games/tabletop games</td>\n",
       "      <td>6.0</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.140887</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>236207086</td>\n",
       "      <td>Neovide, Waterless One-Stop Sous Vide Cooker</td>\n",
       "      <td>No more water containers and vacuum bags. With...</td>\n",
       "      <td>Story\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\...</td>\n",
       "      <td>With our years of experience with products, ou...</td>\n",
       "      <td>[{'rewards': 'Pledge without a reward'}, {'rew...</td>\n",
       "      <td>8</td>\n",
       "      <td>technology</td>\n",
       "      <td>289082.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140606</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2128144913</td>\n",
       "      <td>Lit Cafe</td>\n",
       "      <td>Little Toasts of Happiness</td>\n",
       "      <td>StoryHi! \\r\\nLit Cafe is a small space to prov...</td>\n",
       "      <td>The concept is to offer affordable local food ...</td>\n",
       "      <td>[{'rewards': 'Pledge without a reward'}, {'rew...</td>\n",
       "      <td>7</td>\n",
       "      <td>food/spaces</td>\n",
       "      <td>170.0</td>\n",
       "      <td>12000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>891970407</td>\n",
       "      <td>Runway Tarot &amp; Golden Journey Tarot</td>\n",
       "      <td>When the fashion week come into Tarot.\\r\\nThis...</td>\n",
       "      <td>Story\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\...</td>\n",
       "      <td>COLLABORATION\\r\\nThis is the third time that b...</td>\n",
       "      <td>[{'rewards': 'Pledge without a reward'}, {'rew...</td>\n",
       "      <td>15</td>\n",
       "      <td>art/painting</td>\n",
       "      <td>33599.0</td>\n",
       "      <td>6800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.352060</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 432 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                          name  \\\n",
       "0  1249154571  Bunny Care Clinic Pin and Apparel Collection   \n",
       "1  1276054891               Hustle: A Singaporean Card Game   \n",
       "2   236207086  Neovide, Waterless One-Stop Sous Vide Cooker   \n",
       "3  2128144913                                      Lit Cafe   \n",
       "4   891970407           Runway Tarot & Golden Journey Tarot   \n",
       "\n",
       "                                         description  \\\n",
       "0  A small collection of Bunny themed enamel pins...   \n",
       "1  Hustle: A Singaporean Card Game is a funny and...   \n",
       "2  No more water containers and vacuum bags. With...   \n",
       "3                         Little Toasts of Happiness   \n",
       "4  When the fashion week come into Tarot.\\r\\nThis...   \n",
       "\n",
       "                                   description_story  \\\n",
       "0  Story\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\...   \n",
       "1  Story\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\...   \n",
       "2  Story\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\...   \n",
       "3  StoryHi! \\r\\nLit Cafe is a small space to prov...   \n",
       "4  Story\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\...   \n",
       "\n",
       "                                   description_risks  \\\n",
       "0  We try our best to keep everything on schedule...   \n",
       "1  We want to be frank and honest with all our ge...   \n",
       "2  With our years of experience with products, ou...   \n",
       "3  The concept is to offer affordable local food ...   \n",
       "4  COLLABORATION\\r\\nThis is the third time that b...   \n",
       "\n",
       "                                             rewards  reward_tiers  \\\n",
       "0  [{'rewards': 'Pledge without a reward'}, {'rew...            12   \n",
       "1  [{'rewards': 'Pledge without a reward'}, {'rew...             2   \n",
       "2  [{'rewards': 'Pledge without a reward'}, {'rew...             8   \n",
       "3  [{'rewards': 'Pledge without a reward'}, {'rew...             7   \n",
       "4  [{'rewards': 'Pledge without a reward'}, {'rew...            15   \n",
       "\n",
       "               category   pledged   goal  ... description_risks_90  \\\n",
       "0      art/illustration   14115.0    700  ...             0.000000   \n",
       "1  games/tabletop games       6.0     50  ...             0.000000   \n",
       "2            technology  289082.0  10000  ...             0.140606   \n",
       "3           food/spaces     170.0  12000  ...             0.000000   \n",
       "4          art/painting   33599.0   6800  ...             0.000000   \n",
       "\n",
       "  description_risks_91 description_risks_92 description_risks_93  \\\n",
       "0             0.296369             0.000000                  0.0   \n",
       "1             0.000000             0.000000                  0.0   \n",
       "2             0.000000             0.142717                  0.0   \n",
       "3             0.000000             0.000000                  0.0   \n",
       "4             0.000000             0.000000                  0.0   \n",
       "\n",
       "   description_risks_94  description_risks_95  description_risks_96  \\\n",
       "0              0.000000                   0.0                   0.0   \n",
       "1              0.000000                   0.0                   0.0   \n",
       "2              0.137243                   0.0                   0.0   \n",
       "3              0.000000                   0.0                   0.0   \n",
       "4              0.000000                   0.0                   0.0   \n",
       "\n",
       "   description_risks_97  description_risks_98 description_risks_99  \n",
       "0                   0.0              0.000000             0.000000  \n",
       "1                   0.0              0.140887             0.000000  \n",
       "2                   0.0              0.000000             0.133257  \n",
       "3                   0.0              0.000000             0.000000  \n",
       "4                   0.0              0.352060             0.000000  \n",
       "\n",
       "[5 rows x 432 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create reward tiers feature\n",
    "df = create_rewards_tiers(df)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e42c36c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>description_story</th>\n",
       "      <th>description_risks</th>\n",
       "      <th>rewards</th>\n",
       "      <th>category</th>\n",
       "      <th>all_reward_amount</th>\n",
       "      <th>pledged</th>\n",
       "      <th>goal</th>\n",
       "      <th>...</th>\n",
       "      <th>staff_pick</th>\n",
       "      <th>video</th>\n",
       "      <th>creator_name</th>\n",
       "      <th>creator_url</th>\n",
       "      <th>url</th>\n",
       "      <th>created_at</th>\n",
       "      <th>published_at</th>\n",
       "      <th>launched_at</th>\n",
       "      <th>link</th>\n",
       "      <th>has_video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1249154571</td>\n",
       "      <td>Bunny Care Clinic Pin and Apparel Collection</td>\n",
       "      <td>A small collection of Bunny themed enamel pins...</td>\n",
       "      <td>Story\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHello! My...</td>\n",
       "      <td>We try our best to keep everything on schedule...</td>\n",
       "      <td>[{'rewards': 'Pledge without a reward'}, {'rew...</td>\n",
       "      <td>art/illustration</td>\n",
       "      <td>[0, 12, 14, 20, 25, 32, 35, 78, 80, 85, 155, 130]</td>\n",
       "      <td>14115.0</td>\n",
       "      <td>700</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Labutori</td>\n",
       "      <td>https://www.kickstarter.com/profile/labutori</td>\n",
       "      <td>https://www.kickstarter.com/projects/labutori/...</td>\n",
       "      <td>2022-05-25 03:28:55+00:00</td>\n",
       "      <td>2022-09-09 01:25:20+00:00</td>\n",
       "      <td>2022-09-09 01:25:20+00:00</td>\n",
       "      <td>https://www.kickstarter.com/projects/labutori/...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1276054891</td>\n",
       "      <td>Hustle: A Singaporean Card Game</td>\n",
       "      <td>Hustle: A Singaporean Card Game is a funny and...</td>\n",
       "      <td>Story\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\...</td>\n",
       "      <td>We want to be frank and honest with all our ge...</td>\n",
       "      <td>[{'rewards': 'Pledge without a reward'}, {'rew...</td>\n",
       "      <td>games/tabletop games</td>\n",
       "      <td>[0, 2]</td>\n",
       "      <td>6.0</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://v2.kickstarter.com/1662721387-XBw1i2Sj...</td>\n",
       "      <td>Hustle Singapore</td>\n",
       "      <td>https://www.kickstarter.com/profile/hustlesg</td>\n",
       "      <td>https://www.kickstarter.com/projects/hustlesg/...</td>\n",
       "      <td>2022-08-20 09:52:01+00:00</td>\n",
       "      <td>2022-09-07 13:08:05+00:00</td>\n",
       "      <td>2022-09-07 13:08:05+00:00</td>\n",
       "      <td>https://www.kickstarter.com/projects/hustlesg/...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>236207086</td>\n",
       "      <td>Neovide, Waterless One-Stop Sous Vide Cooker</td>\n",
       "      <td>No more water containers and vacuum bags. With...</td>\n",
       "      <td>Story\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSous vide...</td>\n",
       "      <td>With our years of experience with products, ou...</td>\n",
       "      <td>[{'rewards': 'Pledge without a reward'}, {'rew...</td>\n",
       "      <td>technology</td>\n",
       "      <td>[0, 2, 407, 505, 814, 293, 350, 463]</td>\n",
       "      <td>289082.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>https://v2.kickstarter.com/1662723490-gvkAMr9s...</td>\n",
       "      <td>The Space Tech</td>\n",
       "      <td>https://www.kickstarter.com/profile/thespacetech</td>\n",
       "      <td>https://www.kickstarter.com/projects/thespacet...</td>\n",
       "      <td>2022-06-30 09:28:52+00:00</td>\n",
       "      <td>2022-09-06 13:00:04+00:00</td>\n",
       "      <td>2022-09-06 13:00:04+00:00</td>\n",
       "      <td>https://www.kickstarter.com/projects/thespacet...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2128144913</td>\n",
       "      <td>Lit Cafe</td>\n",
       "      <td>Little Toasts of Happiness</td>\n",
       "      <td>StoryHi! \\nLit Cafe is a small space to provid...</td>\n",
       "      <td>The concept is to offer affordable local food ...</td>\n",
       "      <td>[{'rewards': 'Pledge without a reward'}, {'rew...</td>\n",
       "      <td>food/spaces</td>\n",
       "      <td>[0, 7, 12, 30, 38, 108, 168]</td>\n",
       "      <td>170.0</td>\n",
       "      <td>12000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kay En</td>\n",
       "      <td>https://www.kickstarter.com/profile/hosum</td>\n",
       "      <td>https://www.kickstarter.com/projects/hosum/ho-...</td>\n",
       "      <td>2022-08-30 08:28:52+00:00</td>\n",
       "      <td>2022-09-06 04:29:02+00:00</td>\n",
       "      <td>2022-09-06 04:29:02+00:00</td>\n",
       "      <td>https://www.kickstarter.com/projects/hosum/ho-...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>891970407</td>\n",
       "      <td>Runway Tarot &amp; Golden Journey Tarot</td>\n",
       "      <td>When the fashion week come into Tarot.\\nThis p...</td>\n",
       "      <td>Story\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\...</td>\n",
       "      <td>COLLABORATION\\nThis is the third time that bot...</td>\n",
       "      <td>[{'rewards': 'Pledge without a reward'}, {'rew...</td>\n",
       "      <td>art/painting</td>\n",
       "      <td>[0, 2, 80, 85, 90, 94, 99, 150, 160, 165, 165,...</td>\n",
       "      <td>33599.0</td>\n",
       "      <td>6800</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://v2.kickstarter.com/1662720057-aeWt13h6...</td>\n",
       "      <td>Eugene Leong</td>\n",
       "      <td>https://www.kickstarter.com/profile/locationtarot</td>\n",
       "      <td>https://www.kickstarter.com/projects/locationt...</td>\n",
       "      <td>2022-07-18 14:48:29+00:00</td>\n",
       "      <td>2022-09-05 13:57:35+00:00</td>\n",
       "      <td>2022-09-05 13:57:35+00:00</td>\n",
       "      <td>https://www.kickstarter.com/projects/locationt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                          name  \\\n",
       "0  1249154571  Bunny Care Clinic Pin and Apparel Collection   \n",
       "1  1276054891               Hustle: A Singaporean Card Game   \n",
       "2   236207086  Neovide, Waterless One-Stop Sous Vide Cooker   \n",
       "3  2128144913                                      Lit Cafe   \n",
       "4   891970407           Runway Tarot & Golden Journey Tarot   \n",
       "\n",
       "                                         description  \\\n",
       "0  A small collection of Bunny themed enamel pins...   \n",
       "1  Hustle: A Singaporean Card Game is a funny and...   \n",
       "2  No more water containers and vacuum bags. With...   \n",
       "3                         Little Toasts of Happiness   \n",
       "4  When the fashion week come into Tarot.\\nThis p...   \n",
       "\n",
       "                                   description_story  \\\n",
       "0  Story\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nHello! My...   \n",
       "1  Story\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\...   \n",
       "2  Story\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSous vide...   \n",
       "3  StoryHi! \\nLit Cafe is a small space to provid...   \n",
       "4  Story\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\...   \n",
       "\n",
       "                                   description_risks  \\\n",
       "0  We try our best to keep everything on schedule...   \n",
       "1  We want to be frank and honest with all our ge...   \n",
       "2  With our years of experience with products, ou...   \n",
       "3  The concept is to offer affordable local food ...   \n",
       "4  COLLABORATION\\nThis is the third time that bot...   \n",
       "\n",
       "                                             rewards              category  \\\n",
       "0  [{'rewards': 'Pledge without a reward'}, {'rew...      art/illustration   \n",
       "1  [{'rewards': 'Pledge without a reward'}, {'rew...  games/tabletop games   \n",
       "2  [{'rewards': 'Pledge without a reward'}, {'rew...            technology   \n",
       "3  [{'rewards': 'Pledge without a reward'}, {'rew...           food/spaces   \n",
       "4  [{'rewards': 'Pledge without a reward'}, {'rew...          art/painting   \n",
       "\n",
       "                                   all_reward_amount   pledged   goal  ...  \\\n",
       "0  [0, 12, 14, 20, 25, 32, 35, 78, 80, 85, 155, 130]   14115.0    700  ...   \n",
       "1                                             [0, 2]       6.0     50  ...   \n",
       "2               [0, 2, 407, 505, 814, 293, 350, 463]  289082.0  10000  ...   \n",
       "3                       [0, 7, 12, 30, 38, 108, 168]     170.0  12000  ...   \n",
       "4  [0, 2, 80, 85, 90, 94, 99, 150, 160, 165, 165,...   33599.0   6800  ...   \n",
       "\n",
       "  staff_pick                                              video  \\\n",
       "0          0                                                NaN   \n",
       "1          0  https://v2.kickstarter.com/1662721387-XBw1i2Sj...   \n",
       "2          1  https://v2.kickstarter.com/1662723490-gvkAMr9s...   \n",
       "3          0                                                NaN   \n",
       "4          0  https://v2.kickstarter.com/1662720057-aeWt13h6...   \n",
       "\n",
       "       creator_name                                        creator_url  \\\n",
       "0          Labutori       https://www.kickstarter.com/profile/labutori   \n",
       "1  Hustle Singapore       https://www.kickstarter.com/profile/hustlesg   \n",
       "2    The Space Tech   https://www.kickstarter.com/profile/thespacetech   \n",
       "3            Kay En          https://www.kickstarter.com/profile/hosum   \n",
       "4      Eugene Leong  https://www.kickstarter.com/profile/locationtarot   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.kickstarter.com/projects/labutori/...   \n",
       "1  https://www.kickstarter.com/projects/hustlesg/...   \n",
       "2  https://www.kickstarter.com/projects/thespacet...   \n",
       "3  https://www.kickstarter.com/projects/hosum/ho-...   \n",
       "4  https://www.kickstarter.com/projects/locationt...   \n",
       "\n",
       "                  created_at               published_at  \\\n",
       "0  2022-05-25 03:28:55+00:00  2022-09-09 01:25:20+00:00   \n",
       "1  2022-08-20 09:52:01+00:00  2022-09-07 13:08:05+00:00   \n",
       "2  2022-06-30 09:28:52+00:00  2022-09-06 13:00:04+00:00   \n",
       "3  2022-08-30 08:28:52+00:00  2022-09-06 04:29:02+00:00   \n",
       "4  2022-07-18 14:48:29+00:00  2022-09-05 13:57:35+00:00   \n",
       "\n",
       "                 launched_at  \\\n",
       "0  2022-09-09 01:25:20+00:00   \n",
       "1  2022-09-07 13:08:05+00:00   \n",
       "2  2022-09-06 13:00:04+00:00   \n",
       "3  2022-09-06 04:29:02+00:00   \n",
       "4  2022-09-05 13:57:35+00:00   \n",
       "\n",
       "                                                link has_video  \n",
       "0  https://www.kickstarter.com/projects/labutori/...         0  \n",
       "1  https://www.kickstarter.com/projects/hustlesg/...         1  \n",
       "2  https://www.kickstarter.com/projects/thespacet...         1  \n",
       "3  https://www.kickstarter.com/projects/hosum/ho-...         0  \n",
       "4  https://www.kickstarter.com/projects/locationt...         1  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create all reward amount feature\n",
    "# If lowest reward amount is not 0, the project is either already fully funded or cancelled.\n",
    "# Rewards should be sorted in ascending order, any amount to the right and less than the max means reward is no longer available.\n",
    "df = create_all_reward_amount(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2008d31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Polarity is float which lies in the range of [-1,1] where 1 means positive statement and -1 means a negative statement. Subjective sentences generally refer to personal opinion, emotion or judgment whereas objective refers to factual information. Subjectivity is also a float which lies in the range of [0,1].\n",
    "'''\n",
    "def generate_sentiment_features():\n",
    "    df = df.dropna(subset=['description_story_processed', 'description_risks_processed', 'description_proocessed', 'rewards_processed']) # NOTE: put at top with other dropnas from other features?\n",
    "    df[\"description_story_polarity\"] = df[\"description_story_processed\"].apply(lambda x: \n",
    "                   TextBlob(x).sentiment.polarity)\n",
    "    df[\"description_story_subjectivity\"] = df[\"description_story_processed\"].apply(lambda x: \n",
    "                   TextBlob(x).sentiment.subjectivity)\n",
    "    df[\"description_polarity\"] = df[\"description_proocessed\"].apply(lambda x: \n",
    "                   TextBlob(x).sentiment.polarity)\n",
    "    df[\"description_subjectivity\"] = df[\"description_proocessed\"].apply(lambda x: \n",
    "                   TextBlob(x).sentiment.subjectivity)\n",
    "    df[\"description_risks_polarity\"] = df[\"description_risks_processed\"].apply(lambda x: \n",
    "                   TextBlob(x).sentiment.polarity)\n",
    "    df[\"description_risks_subjectivity\"] = df[\"description_risks_processed\"].apply(lambda x: \n",
    "                   TextBlob(x).sentiment.subjectivity)\n",
    "    df[\"rewards_polarity\"] = df[\"rewards_processed\"].apply(lambda x: \n",
    "                   TextBlob(x).sentiment.polarity)\n",
    "    df[\"rewards_subjectivity\"] = df[\"rewards_processed\"].apply(lambda x: \n",
    "                   TextBlob(x).sentiment.subjectivity)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8913eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate word_count_features(): # omitted description due to word limit, word count likely similar for all projects\n",
    "    df['description_story_word_count'] = df[\"description_story_processed\"].apply(lambda x: len(str(x).split(\" \")))\n",
    "    df['description_risks_word_count'] = df[\"description_risks_processed\"].apply(lambda x: len(str(x).split(\" \")))\n",
    "    df['rewards_word_count'] = df[\"rewards_processed\"].apply(lambda x: len(str(x).split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe3a6baa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E1041] Expected a string, Doc, or bytes as input, but got: <class 'float'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m removal\u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mADV\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPRON\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCCONJ\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPUNCT\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPART\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDET\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mADP\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSPACE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNUM\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSYM\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m tokens \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m story \u001b[38;5;129;01min\u001b[39;00m nlp\u001b[38;5;241m.\u001b[39mpipe(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription_story\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[1;32m      8\u001b[0m    \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(story) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mstr\u001b[39m: tokens\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m    proj_tok \u001b[38;5;241m=\u001b[39m [token\u001b[38;5;241m.\u001b[39mlemma_\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m story \u001b[38;5;28;01mif\u001b[39;00m token\u001b[38;5;241m.\u001b[39mpos_ \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m removal \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m token\u001b[38;5;241m.\u001b[39mis_stop \u001b[38;5;129;01mand\u001b[39;00m token\u001b[38;5;241m.\u001b[39mis_alpha]\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/bt4222/lib/python3.9/site-packages/spacy/language.py:1583\u001b[0m, in \u001b[0;36mLanguage.pipe\u001b[0;34m(self, texts, as_tuples, batch_size, disable, component_cfg, n_process)\u001b[0m\n\u001b[1;32m   1581\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pipe \u001b[38;5;129;01min\u001b[39;00m pipes:\n\u001b[1;32m   1582\u001b[0m         docs \u001b[38;5;241m=\u001b[39m pipe(docs)\n\u001b[0;32m-> 1583\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs:\n\u001b[1;32m   1584\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m doc\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/bt4222/lib/python3.9/site-packages/spacy/util.py:1639\u001b[0m, in \u001b[0;36m_pipe\u001b[0;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[1;32m   1631\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_pipe\u001b[39m(\n\u001b[1;32m   1632\u001b[0m     docs: Iterable[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoc\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1633\u001b[0m     proc: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipe\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1636\u001b[0m     kwargs: Mapping[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m   1637\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoc\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m   1638\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(proc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpipe\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1639\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mpipe(docs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1640\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1641\u001b[0m         \u001b[38;5;66;03m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n\u001b[1;32m   1642\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(kwargs)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/bt4222/lib/python3.9/site-packages/spacy/pipeline/transition_parser.pyx:233\u001b[0m, in \u001b[0;36mpipe\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/bt4222/lib/python3.9/site-packages/spacy/util.py:1588\u001b[0m, in \u001b[0;36mminibatch\u001b[0;34m(items, size)\u001b[0m\n\u001b[1;32m   1586\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m   1587\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(size_)\n\u001b[0;32m-> 1588\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitertools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(batch) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1590\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/bt4222/lib/python3.9/site-packages/spacy/util.py:1639\u001b[0m, in \u001b[0;36m_pipe\u001b[0;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[1;32m   1631\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_pipe\u001b[39m(\n\u001b[1;32m   1632\u001b[0m     docs: Iterable[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoc\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1633\u001b[0m     proc: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipe\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1636\u001b[0m     kwargs: Mapping[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m   1637\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoc\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m   1638\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(proc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpipe\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1639\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mpipe(docs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1640\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1641\u001b[0m         \u001b[38;5;66;03m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n\u001b[1;32m   1642\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(kwargs)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/bt4222/lib/python3.9/site-packages/spacy/pipeline/pipe.pyx:53\u001b[0m, in \u001b[0;36mpipe\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/bt4222/lib/python3.9/site-packages/spacy/util.py:1639\u001b[0m, in \u001b[0;36m_pipe\u001b[0;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[1;32m   1631\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_pipe\u001b[39m(\n\u001b[1;32m   1632\u001b[0m     docs: Iterable[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoc\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1633\u001b[0m     proc: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipe\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1636\u001b[0m     kwargs: Mapping[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m   1637\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoc\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m   1638\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(proc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpipe\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1639\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mpipe(docs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1640\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1641\u001b[0m         \u001b[38;5;66;03m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n\u001b[1;32m   1642\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(kwargs)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/bt4222/lib/python3.9/site-packages/spacy/pipeline/pipe.pyx:53\u001b[0m, in \u001b[0;36mpipe\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/bt4222/lib/python3.9/site-packages/spacy/util.py:1639\u001b[0m, in \u001b[0;36m_pipe\u001b[0;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[1;32m   1631\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_pipe\u001b[39m(\n\u001b[1;32m   1632\u001b[0m     docs: Iterable[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoc\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1633\u001b[0m     proc: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipe\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1636\u001b[0m     kwargs: Mapping[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m   1637\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoc\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m   1638\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(proc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpipe\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1639\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mpipe(docs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1640\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1641\u001b[0m         \u001b[38;5;66;03m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n\u001b[1;32m   1642\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(kwargs)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/bt4222/lib/python3.9/site-packages/spacy/pipeline/transition_parser.pyx:233\u001b[0m, in \u001b[0;36mpipe\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/bt4222/lib/python3.9/site-packages/spacy/util.py:1588\u001b[0m, in \u001b[0;36mminibatch\u001b[0;34m(items, size)\u001b[0m\n\u001b[1;32m   1586\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m   1587\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(size_)\n\u001b[0;32m-> 1588\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitertools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(batch) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1590\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/bt4222/lib/python3.9/site-packages/spacy/util.py:1639\u001b[0m, in \u001b[0;36m_pipe\u001b[0;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[1;32m   1631\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_pipe\u001b[39m(\n\u001b[1;32m   1632\u001b[0m     docs: Iterable[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoc\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1633\u001b[0m     proc: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipe\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1636\u001b[0m     kwargs: Mapping[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m   1637\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoc\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m   1638\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(proc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpipe\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1639\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mpipe(docs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1640\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1641\u001b[0m         \u001b[38;5;66;03m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n\u001b[1;32m   1642\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(kwargs)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/bt4222/lib/python3.9/site-packages/spacy/pipeline/trainable_pipe.pyx:73\u001b[0m, in \u001b[0;36mpipe\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/bt4222/lib/python3.9/site-packages/spacy/util.py:1588\u001b[0m, in \u001b[0;36mminibatch\u001b[0;34m(items, size)\u001b[0m\n\u001b[1;32m   1586\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m   1587\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(size_)\n\u001b[0;32m-> 1588\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitertools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(batch) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1590\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/bt4222/lib/python3.9/site-packages/spacy/util.py:1639\u001b[0m, in \u001b[0;36m_pipe\u001b[0;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[1;32m   1631\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_pipe\u001b[39m(\n\u001b[1;32m   1632\u001b[0m     docs: Iterable[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoc\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1633\u001b[0m     proc: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipe\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1636\u001b[0m     kwargs: Mapping[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m   1637\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoc\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m   1638\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(proc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpipe\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1639\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mpipe(docs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1640\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1641\u001b[0m         \u001b[38;5;66;03m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n\u001b[1;32m   1642\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(kwargs)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/bt4222/lib/python3.9/site-packages/spacy/pipeline/trainable_pipe.pyx:73\u001b[0m, in \u001b[0;36mpipe\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/bt4222/lib/python3.9/site-packages/spacy/util.py:1588\u001b[0m, in \u001b[0;36mminibatch\u001b[0;34m(items, size)\u001b[0m\n\u001b[1;32m   1586\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m   1587\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(size_)\n\u001b[0;32m-> 1588\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitertools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(batch) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1590\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/bt4222/lib/python3.9/site-packages/spacy/language.py:1580\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1577\u001b[0m     docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiprocessing_pipe(texts, pipes, n_process, batch_size)\n\u001b[1;32m   1578\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1579\u001b[0m     \u001b[38;5;66;03m# if n_process == 1, no processes are forked.\u001b[39;00m\n\u001b[0;32m-> 1580\u001b[0m     docs \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_doc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts)\n\u001b[1;32m   1581\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pipe \u001b[38;5;129;01min\u001b[39;00m pipes:\n\u001b[1;32m   1582\u001b[0m         docs \u001b[38;5;241m=\u001b[39m pipe(docs)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/bt4222/lib/python3.9/site-packages/spacy/language.py:1102\u001b[0m, in \u001b[0;36mLanguage._ensure_doc\u001b[0;34m(self, doc_like)\u001b[0m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(doc_like, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m   1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Doc(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab)\u001b[38;5;241m.\u001b[39mfrom_bytes(doc_like)\n\u001b[0;32m-> 1102\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE1041\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtype\u001b[39m(doc_like)))\n",
      "\u001b[0;31mValueError\u001b[0m: [E1041] Expected a string, Doc, or bytes as input, but got: <class 'float'>"
     ]
    }
   ],
   "source": [
    "# generate BOW on description_story \n",
    "# Our spaCy model:\n",
    "# nlp = en_core_web_md.load()\n",
    "# # Tags I want to remove from the text\n",
    "# removal= ['ADV','PRON','CCONJ','PUNCT','PART','DET','ADP','SPACE', 'NUM', 'SYM']\n",
    "# tokens = []\n",
    "# for story in nlp.pipe(df['description_story']):\n",
    "#    if not type(story) is str: tokens.append(\"\")\n",
    "#    proj_tok = [token.lemma_.lower() for token in story if token.pos_ not in removal and not token.is_stop and token.is_alpha]\n",
    "#    tokens.append(proj_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since there could be more than one categories for each project, create new features to split the categories.\n",
    "df['new_category'] = df.category.str.split(\"/\", expand=False)\n",
    "split_cat = pd.DataFrame(df['new_category'].tolist(), columns=['category1', 'category2'])\n",
    "#each project should at least have 1 category, 'category2' can be \"None\". \n",
    "#'category1' being the main category for the project.\n",
    "df = pd.concat([df, split_cat], axis=1)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bt4222",
   "language": "python",
   "name": "bt4222"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b14d2bd7895077ad303f266db7ad1f8a11e285bbfcdfa868008aad211f623e81"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}