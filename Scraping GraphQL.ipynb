{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7f01a93",
   "metadata": {},
   "source": [
    "# Code for scraping - calling Kickstarter GraphQL end point to get text information (Story and Risks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85cc2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import os \n",
    "import ast\n",
    "import json\n",
    "import time\n",
    "from requests.exceptions import ConnectionError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57486dac",
   "metadata": {},
   "source": [
    "## Do not run. Import df_1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c7a574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base = \"/Users/ivankoh/Downloads/kickstarter data/\"\n",
    "# filepaths = [base + f for f in os.listdir(base) if f.endswith('.csv')]\n",
    "# df = pd.concat(map(pd.read_csv, filepaths))\n",
    "# df_1 = df.drop_duplicates(subset=['id'])\n",
    "# df_1['main_url'] = df_1['urls'].apply(lambda x: eval(x)['web']['project'])\n",
    "# print(len(df))\n",
    "# print(len(df_1))\n",
    "\n",
    "# # export out \n",
    "# df_1.to_csv(\"df_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29991fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv(\"/Users/ivankoh/Documents/GitHub/Kickstarter-Funding-Optimization/kickstart_data_merged_with_empty.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bd2336",
   "metadata": {},
   "source": [
    "## Sample code for extracting story and risk\n",
    "As there are many rows of data, we split the work among the group members so each person takes a bucket of urls to use to scrape. As such, running the below with the full dataset will take approximately 2 weeks, running 24 hours a day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016701b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slug(url):\n",
    "    return re.search('/projects/(.*)\\?', url).group(1)\n",
    "\n",
    "# get the slug from the urls. the slug is the input to the GraphQL API call \n",
    "slugs = list(map(get_slug, df_1['main_url'].tolist()))\n",
    "# while iterating through all projects, add the story and risk to these lists. At the end len of both list \n",
    "# should be the same as the len of the dataframe. if all good then add as columns to the dataframe df. \n",
    "story_list2 = []\n",
    "risk_list2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79db610f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a new Session \n",
    "s = requests.Session()\n",
    "\n",
    "query = \"\"\"\n",
    "query Campaign($slug: String!) {\n",
    "  project(slug: $slug) {\n",
    "    risks\n",
    "    story(assetWidth: 680)\n",
    "  }\n",
    "}\"\"\"\n",
    "\n",
    "# PARAMS\n",
    "counter = 0\n",
    "block_number = 0\n",
    "agents = [\n",
    "         \"Mozilla/5.0 (Symbian/3; Series60/5.2 NokiaN8-00/012.002; Profile/MIDP-2.1 Configuration/CLDC-1.1 ) AppleWebKit/533.4 (KHTML, like Gecko) NokiaBrowser/7.3.0 Mobile Safari/533.4 3gpp-gba\",\n",
    "         \"Mozilla/5.0 (Linux; Android 5.0; Lenovo S60-a Build/LRX21T) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 YaBrowser/17.3.1.383.00 Mobile Safari/E7FBAF\",\n",
    "         \"Mozilla/5.0 (iPhone; CPU iPhone OS 15_5 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148 Instagram 244.0.0.12.112 (iPhone12,1; iOS 15_5; en_US; en-US; scale=2.00; 828x1792; 383361019)\",\n",
    "         \"Mozilla/5.0 (Linux; U; Android 2.2.1; en-US; GT-S5830 Build/FROYO) AppleWebKit/534.31 (KHTML, like Gecko) UCBrowser/9.0.1.275 U3/0.8.0 Mobile Safari/534.31\",\n",
    "         \"Mozilla/5.0 (Linux; Android 11; Redmi Note 8 Pro) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Mobile Safari/537.36\"\n",
    "         ]\n",
    "\n",
    "# pause for 30 seconds every 5 iterations\n",
    "for i in range(67115, 81405):\n",
    "    slug = slugs[i]\n",
    "    if counter == 5:\n",
    "        print(\"TAKING A NAP ZZZ...\")\n",
    "        time.sleep(30)\n",
    "        counter = 0\n",
    "    counter += 1\n",
    "    print(f\"--------{slug}------\")\n",
    "    # POST request to GraphQL API situated in kickstarter domain \n",
    "    # response from POST request should contain the story and risks\n",
    "    connect_try = 0\n",
    "    not_found = True\n",
    "    while connect_try < 30 and not_found:       \n",
    "        try:\n",
    "            r = s.post(\"https://www.kickstarter.com/graph\",\n",
    "                headers = {\n",
    "                  'content-type': 'application/json',\n",
    "                  'x-csrf-token': 'bL5nMRm5s147N8RxvNcth-E8NAOt3SprGYtvvKsVLnuZ3XwQ71cy1zrDfjIAGTCHV0obMRNqRMbBJT7nF2ZSAA',\n",
    "                  'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:50.0) Gecko/20100101 Firefox/50.0',\n",
    "                  'cookie': '_ksr_session=eus10UNK7iB%2FwIMXafXg5yJdYvRD7rHlR%2Ba1KEbUnB5EKTgQxNKEIqrp%2BIyjRC%2FNXw76u4Eki4AsiBom5M1LKNJKWCD65CBzeegWrk2%2FRV9Sht6dlOKplCATNdrmEIIa0Bt%2FKKGnT2m9ID1nTCduj73%2BdeJK663MNcbYWXBHkFyZJgUKh4JcCx3hL0UF2quVeBvfV45M0CNrT1j4DchvTlFBn%2BpE37ZaGldNz7BF0RAcCjIZrt%2FzNkxugCaFfWEPjxh9amOCvytIcdjxOaE68AAmHuU%3D--RPNmoWC%2FGnWTmsfw--9466UG%2Bqs2V%2F8B8zFtXUig%3D%3D'\n",
    "                },\n",
    "                json = {\n",
    "                    \"operationName\":\"Campaign\",\n",
    "                    \"variables\":{\n",
    "                        \"slug\": slug\n",
    "                    },\n",
    "                    \"query\": query\n",
    "                })\n",
    "            not_found = False\n",
    "        except ConnectionError:\n",
    "            print(\"Connection Error\")\n",
    "            time.sleep(5)\n",
    "            connect_try += 1\n",
    "    try:\n",
    "        result = r.json()\n",
    "        print(\"-------STORY--------\")\n",
    "        story_html = result[\"data\"][\"project\"][\"story\"]\n",
    "        soup = BeautifulSoup(story_html, 'html.parser')\n",
    "        curr_story = []\n",
    "        for i in soup.find_all('p'):\n",
    "            print(i.get_text())\n",
    "            curr_story.append(i.get_text())\n",
    "        story_list2.append(\" \".join(curr_story) if curr_story else \"\")\n",
    "\n",
    "        print(\"-------RISKS--------\")\n",
    "        print(result[\"data\"][\"project\"][\"risks\"])\n",
    "        risk_list2.append(result[\"data\"][\"project\"][\"risks\"] if result[\"data\"][\"project\"][\"risks\"] else \"\")\n",
    "    except:\n",
    "        print(r)\n",
    "        story_list2.append(\"\")\n",
    "        risk_list2.append(\"\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3537574",
   "metadata": {},
   "source": [
    "# Saving Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9927e871",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE LIST IN LOCAL FOR USE LATER. NAME FILE AS {from}_{to]_{story/risk}.json\n",
    "story_file_name = \"/Users/ivankoh/Downloads/bt4222 data/44135_81404_story\" #CHANGE THIS\n",
    "risk_file_name = \"/Users/ivankoh/Downloads/bt4222 data/44135_81404_risk\" #CHANGE THIS \n",
    "\n",
    "story_file_name += \".json\"\n",
    "risk_file_name += \".json\"\n",
    "\n",
    "with open(story_file_name, 'w') as f:\n",
    "    # indent=2 is not needed but makes the file human-readable \n",
    "    # if the data is nested\n",
    "    json.dump(story_list2, f, indent=2) \n",
    "\n",
    "with open(risk_file_name, 'w') as f:\n",
    "    # indent=2 is not needed but makes the file human-readable \n",
    "    # if the data is nested\n",
    "    json.dump(risk_list2, f, indent=2) \n",
    "    \n",
    "# with open(story_file_name, 'r') as f:\n",
    "#     story_subset = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c3e5fc",
   "metadata": {},
   "source": [
    "# Checking data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17974e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"risk:\", len(risk_list2),\"\\n\", \"story:\", len(story_list2))\n",
    "44135 + 37270  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbc4fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/ivankoh/Downloads/bt4222 data/44135_48799_risk.json', 'r') as f:\n",
    "    risk_subset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2b93cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(risk_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cb9997",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LATEST CALL DF ROW\", \"\\n\")\n",
    "print(df_1.iloc[81405-1]['blurb'])\n",
    "\n",
    "print(\"LATEST STORY IN LIST\", \"\\n\")\n",
    "print(story_list2[-1])\n",
    "\n",
    "print(\"LATEST RISK IN LIST\", \"\\n\")\n",
    "print(risk_list2[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (bt4222)",
   "language": "python",
   "name": "bt4222"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
