{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score, recall_score, classification_report,confusion_matrix\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24756, 579)\n",
      "(4369, 579)\n"
     ]
    }
   ],
   "source": [
    "train_path = max(glob.glob('./data/train/*.csv'), key=os.path.getctime) \n",
    "test_path = max(glob.glob('./data/test/*.csv'), key=os.path.getctime) \n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['reward_tiers', 'min_reward', 'max_reward', 'goal', 'state',\n",
      "       'staff_pick', 'has_video', 'rewards_0', 'rewards_1', 'rewards_2',\n",
      "       'rewards_3', 'rewards_4', 'rewards_5', 'rewards_6', 'rewards_7',\n",
      "       'rewards_8', 'rewards_9', 'rewards_10', 'rewards_11', 'rewards_12',\n",
      "       'rewards_13', 'rewards_14', 'rewards_15', 'rewards_16', 'rewards_17'],\n",
      "      dtype='object')\n",
      "Index(['reward_tiers', 'min_reward', 'max_reward', 'goal', 'state',\n",
      "       'staff_pick', 'has_video', 'rewards_0', 'rewards_1', 'rewards_2',\n",
      "       'rewards_3', 'rewards_4', 'rewards_5', 'rewards_6', 'rewards_7',\n",
      "       'rewards_8', 'rewards_9', 'rewards_10', 'rewards_11', 'rewards_12',\n",
      "       'rewards_13', 'rewards_14', 'rewards_15', 'rewards_16', 'rewards_17'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train_df.columns[:25])\n",
    "print(test_df.columns[:25])\n",
    "# test_df.columns == train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_to_drop = ['rewards', 'deadline', 'launched_at', 'rewards_processed', 'created_at',\n",
    "# 'description_processed', 'description_story_processed','description_risks_processed',\n",
    "# 'id', 'name', 'description', 'description_story', 'description_risks', 'video', 'state',\n",
    "# 'location', 'category']\n",
    "\n",
    "#features that are dependent on time and the final outcome\n",
    "\n",
    "X_train, y_train = train_df.drop('state', axis=1), train_df['state']\n",
    "X_test, y_test = test_df.drop('state', axis=1), test_df['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine train and test data set tgt\n",
    "\n",
    "X = pd.concat([X_train, X_test])\n",
    "y = pd.concat([y_train, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17482, 579)\n",
      "(7274, 579)\n",
      "(24756, 578)\n",
      "(24756,)\n",
      "(4369, 578)\n",
      "(4369,)\n"
     ]
    }
   ],
   "source": [
    "# Check if dataset is balanced\n",
    "print(train_df[train_df.state == 1].shape)\n",
    "print(train_df[train_df.state == 0].shape)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([dtype('float64'), dtype('int64')], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure all data are of integer of float type\n",
    "X_train.dtypes.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bandy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py:793: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.51507\n",
      "[1]\tvalidation_0-logloss:0.41499\n",
      "[2]\tvalidation_0-logloss:0.34948\n",
      "[3]\tvalidation_0-logloss:0.30554\n",
      "[4]\tvalidation_0-logloss:0.27589\n",
      "[5]\tvalidation_0-logloss:0.25396\n",
      "[6]\tvalidation_0-logloss:0.23612\n",
      "[7]\tvalidation_0-logloss:0.22233\n",
      "[8]\tvalidation_0-logloss:0.21266\n",
      "[9]\tvalidation_0-logloss:0.20380\n",
      "[10]\tvalidation_0-logloss:0.19950\n",
      "[11]\tvalidation_0-logloss:0.19253\n",
      "[12]\tvalidation_0-logloss:0.18869\n",
      "[13]\tvalidation_0-logloss:0.18627\n",
      "[14]\tvalidation_0-logloss:0.18364\n",
      "[15]\tvalidation_0-logloss:0.18110\n",
      "[16]\tvalidation_0-logloss:0.17900\n",
      "[17]\tvalidation_0-logloss:0.17695\n",
      "[18]\tvalidation_0-logloss:0.17434\n",
      "[19]\tvalidation_0-logloss:0.17321\n",
      "[20]\tvalidation_0-logloss:0.17162\n",
      "[21]\tvalidation_0-logloss:0.16968\n",
      "[22]\tvalidation_0-logloss:0.16924\n",
      "[23]\tvalidation_0-logloss:0.16857\n",
      "[24]\tvalidation_0-logloss:0.16798\n",
      "[25]\tvalidation_0-logloss:0.16777\n",
      "[26]\tvalidation_0-logloss:0.16739\n",
      "[27]\tvalidation_0-logloss:0.16641\n",
      "[28]\tvalidation_0-logloss:0.16585\n",
      "[29]\tvalidation_0-logloss:0.16544\n",
      "[30]\tvalidation_0-logloss:0.16473\n",
      "[31]\tvalidation_0-logloss:0.16379\n",
      "[32]\tvalidation_0-logloss:0.16332\n",
      "[33]\tvalidation_0-logloss:0.16326\n",
      "[34]\tvalidation_0-logloss:0.16258\n",
      "[35]\tvalidation_0-logloss:0.16203\n",
      "[36]\tvalidation_0-logloss:0.16212\n",
      "[37]\tvalidation_0-logloss:0.16187\n",
      "[38]\tvalidation_0-logloss:0.16163\n",
      "[39]\tvalidation_0-logloss:0.16071\n",
      "[40]\tvalidation_0-logloss:0.16033\n",
      "[41]\tvalidation_0-logloss:0.16008\n",
      "[42]\tvalidation_0-logloss:0.16013\n",
      "[43]\tvalidation_0-logloss:0.16001\n",
      "[44]\tvalidation_0-logloss:0.16022\n",
      "[45]\tvalidation_0-logloss:0.16032\n",
      "[46]\tvalidation_0-logloss:0.16103\n",
      "[47]\tvalidation_0-logloss:0.16099\n",
      "[48]\tvalidation_0-logloss:0.16084\n",
      "[49]\tvalidation_0-logloss:0.16146\n",
      "[50]\tvalidation_0-logloss:0.16104\n",
      "[51]\tvalidation_0-logloss:0.16048\n",
      "[52]\tvalidation_0-logloss:0.16035\n"
     ]
    }
   ],
   "source": [
    "#Default model\n",
    "model_xgboost_default = xgb.XGBClassifier()\n",
    "\n",
    "model_xgboost_default.fit(X_train,\n",
    "                  y_train,\n",
    "                  early_stopping_rounds=10,\n",
    "                  eval_set=[(X_test, y_test)],\n",
    "                  verbose=True)\n",
    "\n",
    "xgb_train_default_predict = model_xgboost_default.predict(X_train)\n",
    "xgb_test_default_predict = model_xgboost_default.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate Model Performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6848   426]\n",
      " [  126 17356]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      7274\n",
      "           1       0.98      0.99      0.98     17482\n",
      "\n",
      "    accuracy                           0.98     24756\n",
      "   macro avg       0.98      0.97      0.97     24756\n",
      "weighted avg       0.98      0.98      0.98     24756\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, xgb_train_default_predict))\n",
    "print(classification_report(y_train, xgb_train_default_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1085  197]\n",
      " [  80 3007]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.85      0.89      1282\n",
      "           1       0.94      0.97      0.96      3087\n",
      "\n",
      "    accuracy                           0.94      4369\n",
      "   macro avg       0.93      0.91      0.92      4369\n",
      "weighted avg       0.94      0.94      0.94      4369\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, xgb_test_default_predict))\n",
    "print(classification_report(y_test, xgb_test_default_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'binary:logistic',\n",
       " 'use_label_encoder': False,\n",
       " 'base_score': 0.5,\n",
       " 'booster': 'gbtree',\n",
       " 'callbacks': None,\n",
       " 'colsample_bylevel': 1,\n",
       " 'colsample_bynode': 1,\n",
       " 'colsample_bytree': 1,\n",
       " 'early_stopping_rounds': None,\n",
       " 'enable_categorical': False,\n",
       " 'eval_metric': 'auc',\n",
       " 'gamma': 0,\n",
       " 'gpu_id': -1,\n",
       " 'grow_policy': 'depthwise',\n",
       " 'importance_type': None,\n",
       " 'interaction_constraints': '',\n",
       " 'learning_rate': 0.300000012,\n",
       " 'max_bin': 256,\n",
       " 'max_cat_to_onehot': 4,\n",
       " 'max_delta_step': 0,\n",
       " 'max_depth': 6,\n",
       " 'max_leaves': 0,\n",
       " 'min_child_weight': 1,\n",
       " 'missing': nan,\n",
       " 'monotone_constraints': '()',\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': 0,\n",
       " 'num_parallel_tree': 1,\n",
       " 'predictor': 'auto',\n",
       " 'random_state': 0,\n",
       " 'reg_alpha': 0,\n",
       " 'reg_lambda': 1,\n",
       " 'sampling_method': 'uniform',\n",
       " 'scale_pos_weight': 1,\n",
       " 'subsample': 1,\n",
       " 'tree_method': 'exact',\n",
       " 'validate_parameters': 1,\n",
       " 'verbosity': None}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgboost_default.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Train: 0.9891\n",
      "AUC Valid: 0.9750\n"
     ]
    }
   ],
   "source": [
    "# y_train_pred = model_xgboost_complex.predict_proba(X_train)[:,1]\n",
    "# y_test_pred = model_xgboost_complex.predict_proba(X_test)[:,1] # Slicing to obtain prob of observation being 1\n",
    "\n",
    "# print(\"AUC Train: {:.4f}\\nAUC Valid: {:.4f}\".format(roc_auc_score(y_train, y_train_pred),\n",
    "#                                                     roc_auc_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter Tuning**\n",
    "\n",
    "We will use GridSearchCV for hyperparameter tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': [0.02, 0.05, 0.1],\n",
       " 'max_depth': [2, 3, 5],\n",
       " 'n_estimators': [50, 100, 150]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate_list = [0.02, 0.05, 0.1]\n",
    "max_depth_list = [2, 3, 5]\n",
    "n_estimators_list = [50, 100, 150]\n",
    "\n",
    "params_dict = {\"learning_rate\": learning_rate_list,\n",
    "               \"max_depth\": max_depth_list,\n",
    "               \"n_estimators\": n_estimators_list}\n",
    "\n",
    "num_combinations = 1\n",
    "for v in params_dict.values(): num_combinations *= len(v) \n",
    "\n",
    "print(num_combinations)\n",
    "params_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 10 candidates, totalling 60 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\GitHub\\Kickstarter-Funding-Optimization\\xgboost.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/GitHub/Kickstarter-Funding-Optimization/xgboost.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m cv_method \u001b[39m=\u001b[39m RepeatedStratifiedKFold(n_splits\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/GitHub/Kickstarter-Funding-Optimization/xgboost.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                                     n_repeats\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/GitHub/Kickstarter-Funding-Optimization/xgboost.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                                     random_state\u001b[39m=\u001b[39m\u001b[39m2022\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/GitHub/Kickstarter-Funding-Optimization/xgboost.ipynb#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m model_xgboost_tuning \u001b[39m=\u001b[39m RandomizedSearchCV(estimator\u001b[39m=\u001b[39mxgb\u001b[39m.\u001b[39mXGBClassifier(),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/GitHub/Kickstarter-Funding-Optimization/xgboost.ipynb#X21sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                                 param_distributions \u001b[39m=\u001b[39m params_dict,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/GitHub/Kickstarter-Funding-Optimization/xgboost.ipynb#X21sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                                 cv\u001b[39m=\u001b[39mcv_method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/GitHub/Kickstarter-Funding-Optimization/xgboost.ipynb#X21sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                                 verbose\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/GitHub/Kickstarter-Funding-Optimization/xgboost.ipynb#X21sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m                                 random_state\u001b[39m=\u001b[39m\u001b[39m2022\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/GitHub/Kickstarter-Funding-Optimization/xgboost.ipynb#X21sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m model_xgboost_tuning\u001b[39m.\u001b[39;49mfit(X, y)\n",
      "File \u001b[1;32mc:\\Users\\bandy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    877\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\bandy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1753\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1751\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1752\u001b[0m     \u001b[39m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1753\u001b[0m     evaluate_candidates(\n\u001b[0;32m   1754\u001b[0m         ParameterSampler(\n\u001b[0;32m   1755\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_distributions, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_iter, random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state\n\u001b[0;32m   1756\u001b[0m         )\n\u001b[0;32m   1757\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\bandy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    815\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    817\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    819\u001b[0m         )\n\u001b[0;32m    820\u001b[0m     )\n\u001b[1;32m--> 822\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    823\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    824\u001b[0m         clone(base_estimator),\n\u001b[0;32m    825\u001b[0m         X,\n\u001b[0;32m    826\u001b[0m         y,\n\u001b[0;32m    827\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    828\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    829\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    830\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    831\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    832\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    833\u001b[0m     )\n\u001b[0;32m    834\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    835\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    836\u001b[0m     )\n\u001b[0;32m    837\u001b[0m )\n\u001b[0;32m    839\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    840\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    844\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\bandy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1043\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1035\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1040\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1044\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32mc:\\Users\\bandy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bandy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    780\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\bandy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\bandy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\bandy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\bandy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\bandy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\bandy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\bandy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:575\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    574\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 575\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\bandy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py:1400\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1379\u001b[0m model, metric, params, early_stopping_rounds, callbacks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_configure_fit(\n\u001b[0;32m   1380\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1381\u001b[0m )\n\u001b[0;32m   1382\u001b[0m train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1383\u001b[0m     missing\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmissing,\n\u001b[0;32m   1384\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1397\u001b[0m     enable_categorical\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menable_categorical,\n\u001b[0;32m   1398\u001b[0m )\n\u001b[1;32m-> 1400\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[0;32m   1401\u001b[0m     params,\n\u001b[0;32m   1402\u001b[0m     train_dmatrix,\n\u001b[0;32m   1403\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[0;32m   1404\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[0;32m   1405\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[0;32m   1406\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[0;32m   1407\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[0;32m   1408\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[0;32m   1409\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   1410\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m   1411\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   1412\u001b[0m )\n\u001b[0;32m   1414\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n\u001b[0;32m   1415\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective \u001b[39m=\u001b[39m params[\u001b[39m\"\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\bandy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:575\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    574\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 575\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\bandy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[0;32m    182\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bandy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:1778\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_features(dtrain)\n\u001b[0;32m   1777\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1778\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[0;32m   1779\u001b[0m                                             ctypes\u001b[39m.\u001b[39;49mc_int(iteration),\n\u001b[0;32m   1780\u001b[0m                                             dtrain\u001b[39m.\u001b[39;49mhandle))\n\u001b[0;32m   1781\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1782\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Custom cross-validation method\n",
    "cv_method = RepeatedStratifiedKFold(n_splits=3, \n",
    "                                    n_repeats=2, \n",
    "                                    random_state=2022)\n",
    "\n",
    "model_xgboost_tuning = RandomizedSearchCV(estimator=xgb.XGBClassifier(),\n",
    "                                param_distributions = params_dict,\n",
    "                                cv=cv_method,\n",
    "                                scoring='roc_auc',\n",
    "                                return_train_score=True,\n",
    "                                verbose=2,\n",
    "                                random_state=2022)\n",
    "\n",
    "model_xgboost_tuning.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.978351</td>\n",
       "      <td>0.996028</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.969464</td>\n",
       "      <td>0.972784</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>0.965955</td>\n",
       "      <td>0.970468</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.963603</td>\n",
       "      <td>0.972855</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.960503</td>\n",
       "      <td>0.969132</td>\n",
       "      <td>0.02</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>0.958736</td>\n",
       "      <td>0.961239</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.956816</td>\n",
       "      <td>0.960620</td>\n",
       "      <td>0.02</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>0.953039</td>\n",
       "      <td>0.956575</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.950087</td>\n",
       "      <td>0.952266</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0.948468</td>\n",
       "      <td>0.951616</td>\n",
       "      <td>0.02</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank_test_score  mean_test_score  mean_train_score param_learning_rate  \\\n",
       "3                1         0.978351          0.996028                 0.1   \n",
       "4                2         0.969464          0.972784                 0.1   \n",
       "9                3         0.965955          0.970468                 0.1   \n",
       "1                4         0.963603          0.972855                0.05   \n",
       "0                5         0.960503          0.969132                0.02   \n",
       "7                6         0.958736          0.961239                0.05   \n",
       "6                7         0.956816          0.960620                0.02   \n",
       "5                8         0.953039          0.956575                0.05   \n",
       "8                9         0.950087          0.952266                0.02   \n",
       "2               10         0.948468          0.951616                0.02   \n",
       "\n",
       "  param_max_depth param_n_estimators  \n",
       "3               5                150  \n",
       "4               2                100  \n",
       "9               3                 50  \n",
       "1               5                 50  \n",
       "0               5                100  \n",
       "7               2                100  \n",
       "6               3                150  \n",
       "5               3                 50  \n",
       "8               2                150  \n",
       "2               3                100  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cv_results = pd.DataFrame(model_xgboost_tuning.cv_results_)\n",
    "df_cv_results = df_cv_results[['rank_test_score','mean_test_score','mean_train_score',\n",
    "                               'param_learning_rate', 'param_max_depth', 'param_n_estimators']]\n",
    "df_cv_results.sort_values(by='rank_test_score', inplace=True)\n",
    "df_cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model\n",
    "Using best parameters from above step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken for the program execution 50.61250686645508\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.93745   0.85335   0.89343      1282\n",
      "           1    0.94129   0.97635   0.95850      3087\n",
      "\n",
      "    accuracy                        0.94026      4369\n",
      "   macro avg    0.93937   0.91485   0.92596      4369\n",
      "weighted avg    0.94016   0.94026   0.93940      4369\n",
      "\n",
      "0.9148532899527838\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "model_xgboost_fin = xgb.XGBClassifier(n_estimators= 150, max_depth = 5, learning_rate = 0.1)\n",
    "\n",
    "# model_xgboost_fin = xgb.XGBClassifier(**model_xgboost_tuning.best_params_)\n",
    "model_xgboost_fin.fit(X_train, y_train)\n",
    "y_pred_test = model_xgboost_fin.predict(X_test)\n",
    "\n",
    "time_taken = time.time() - start_time\n",
    "print(\"Total time taken for the program execution\", time_taken) # seconds\n",
    "print(classification_report(y_test, y_pred_test, digits=5))\n",
    "print(roc_auc_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rewards_1</td>\n",
       "      <td>0.109209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>staff_pick</td>\n",
       "      <td>0.029009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>rewards_65</td>\n",
       "      <td>0.025735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reward_tiers</td>\n",
       "      <td>0.018304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>rewards_76</td>\n",
       "      <td>0.017719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rewards_5</td>\n",
       "      <td>0.015256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>success_rate</td>\n",
       "      <td>0.014864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rewards_0</td>\n",
       "      <td>0.012535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>goal</td>\n",
       "      <td>0.011617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>rewards_60</td>\n",
       "      <td>0.011501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Feature  Importance\n",
       "7       rewards_1    0.109209\n",
       "4      staff_pick    0.029009\n",
       "71     rewards_65    0.025735\n",
       "0    reward_tiers    0.018304\n",
       "82     rewards_76    0.017719\n",
       "11      rewards_5    0.015256\n",
       "421  success_rate    0.014864\n",
       "6       rewards_0    0.012535\n",
       "3            goal    0.011617\n",
       "66     rewards_60    0.011501"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_colums = [c for c in X_train.columns if c not in ['state']]\n",
    "\n",
    "df_var_imp = pd.DataFrame({\"Feature\": var_colums,\n",
    "                           \"Importance\": model_xgboost_fin.feature_importances_})\\\n",
    "                        .sort_values(by='Importance', ascending=False)\n",
    "df_var_imp[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "3d8ed9d5f82d3a6b03b0c02db761342dfdb80b03ec2829061c6d06f1ae9d9b4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
